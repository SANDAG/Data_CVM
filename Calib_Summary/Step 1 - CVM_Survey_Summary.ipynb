{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import openmatrix as omx\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "_join = os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the model directory\n",
    "calibration_data_dir = r\"C:\\_projects\\summary\\calibration_targets_data\"\n",
    "\n",
    "# path to the model output directory\n",
    "calibration_raw_data_dir = _join(calibration_data_dir)\n",
    "\n",
    "# path to the model data directory\n",
    "model_dir = r\"C:\\_projects\\ABM_VY\\src\\asim-cvm\"\n",
    "model_data_dir = _join(model_dir, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional functions\n",
    "def array2df(array, cols =['orig', 'dest', 'od']):\n",
    "    \"\"\"\n",
    "    Convert a numpy array to a dataframe\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(array)\n",
    "    df = pd.melt(df.reset_index(), id_vars='index', value_vars=df.columns)\n",
    "    df['index'] = df['index'] + 1\n",
    "    df['variable'] = df['variable'] + 1\n",
    "    df.columns = cols\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## household_attractor\n",
    "## establishment_attractor\n",
    "## cvm_accessibility\n",
    "## route_generation\n",
    "## route_generation_tnc\n",
    "## route_purpose_and_vehicle\n",
    "## route_start_time\n",
    "## route_origination_type\n",
    "## route_origination\n",
    "## route_terminal_type\n",
    "## route_terminal\n",
    "## route_stops\n",
    "## write_cvm_trip_matrices\n",
    "## write_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Household Attractor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input data\n",
    "df_days = pd.read_csv(_join(calibration_raw_data_dir, r\"export_day_weights.csv\"))\n",
    "households = pd.read_csv(_join(calibration_raw_data_dir, r\"export_hh_weights_mgra.csv\"))\n",
    "persons = pd.read_csv(_join(calibration_raw_data_dir, r\"export_person_weights.csv\"))\n",
    "\n",
    "#df_days.set_index('day_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only eligible participants and weekdays (Mon-Thu)\n",
    "df_days = df_days[(df_days['is_participant']>0) & (df_days['travel_dow'].isin([1,2,3,4]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delivery Variable Definitions\n",
    "\n",
    "- delivery_2:  Delivery on travel day: Food was delivered to home (e.g., take-out, groceries)\n",
    "- delivery_3:  Delivery on travel day: Someone came to do work at home (e.g., landscaping, plumber, housecleaning)\n",
    "- delivery_5:  Delivery on travel day: Received package AT HOME (e.g., USPS, FedEx, UPS)\n",
    "- delivery_6:  Delivery on travel day: Received personal packages AT WORK\n",
    "- delivery_7:  Delivery on travel day: Received packages at OFFSITE LOCKER (e.g., Amazon locker, package pick-up point)\n",
    "- delivery_8:  Delivery on travel day: Other item delivered to home (e.g., appliance)\n",
    "- delivery_996:  Delivery on travel day: None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anywhere that the input for Delivery column is 995, Missing Response, set the value to zero\n",
    "del_cols = [col for col in df_days if \"delivery_\" in col]\n",
    "df_days[del_cols] = df_days[del_cols].replace(995, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the max delivery by hh by day\n",
    "cols = del_cols + ['day_weight']\n",
    "\n",
    "# Group by 'hh_id' and 'day_num', then check if any column in the group is equal to 1\n",
    "df_deliv = df_days.groupby(['hh_id', 'day_num'])[cols].max().reset_index()\n",
    "\n",
    "#df_deliv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    if \"delivery_\" in col:\n",
    "        print(f\"{col}: {df_deliv[df_deliv[col]==1][col].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode\n",
    "df_deliv['Food'] = df_deliv['delivery_2'] * df_deliv['day_weight']\n",
    "df_deliv['Service'] = df_deliv['delivery_3'] * df_deliv['day_weight']\n",
    "df_deliv['Package'] = np.maximum(df_deliv['delivery_5'], df_deliv['delivery_8']) * df_deliv['day_weight']\n",
    "hh_deliv = df_deliv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = ['Food', 'Service', 'Package']\n",
    "result = round(hh_deliv[use_cols].sum()/hh_deliv['day_weight'].sum(),6)\n",
    "svy_hh_group = pd.DataFrame(result, columns=['Percentage']).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding additional attributes from the Households file\n",
    "\n",
    "# What column to include from the households file\n",
    "cols_hh = ['hh_id','MGRA', 'num_people', 'income_detailed', 'num_vehicles']\n",
    "\n",
    "hh = hh_deliv.merge(households[cols_hh], how='left', on='hh_id')\n",
    "hh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabel the income categories as follows:\n",
    "\n",
    "    # HHTS Category ---- Summary Category\n",
    "    # 1  Less than $15,000 ----1\n",
    "    # 2 $15,000-$24,999 ---- 1\n",
    "    # 3 $25,000-$34,999 ---- 1\n",
    "    # 4 $35,000-$49,999 ---- 1\n",
    "    # 5 $50,000-$74,999 ---- 2\n",
    "    # 6 $75,000-$99,999 ---- 2\n",
    "    # 7 $100,000-$149,999 ---- 3\n",
    "    # 8 $150,000-$199,999 ---- 3\n",
    "    # 9 $200,000-$249,999 ---- 4\n",
    "    # 10 $250,000 or more ---- 4\n",
    "    # 999 Prefer not to answer ---- 0\n",
    "\n",
    "hhts_inc_cat = {\n",
    "    1 : 1,\n",
    "    2 : 1,\n",
    "    3 : 1,\n",
    "    4 : 1,\n",
    "    5 : 2,\n",
    "    6 : 2,\n",
    "    7 : 3,\n",
    "    8 : 3,\n",
    "    9 : 4,\n",
    "    10 : 4,\n",
    "    999 : 0\n",
    "}\n",
    "\n",
    "\n",
    "hh['Income_Group'] = hh['income_detailed'].map(hhts_inc_cat)\n",
    "\n",
    "# Relabel the hh size categories as follows:\n",
    "\n",
    "    # HHTS Category ---- Summary Category\n",
    "    # 1   ----1\n",
    "    # 2  ---- 2\n",
    "    # 3  ---- 3\n",
    "    # 4  ---- 4\n",
    "    # 5  ---- 5\n",
    "    # 6  ---- 6+\n",
    "    # 7  ---- 6+\n",
    "    # 8  ---- 6+\n",
    "    # 9  ---- 6+\n",
    "    # 10  ---- 6+\n",
    "    # 10  ---- 6+\n",
    "    # 10  ---- 6+\n",
    "    # 10  ---- 6+\n",
    "    # 995 ---- 0\n",
    "\n",
    "hhsize_category_mapping = {\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6+',\n",
    "    7: '6+',\n",
    "    8: '6+',\n",
    "    9: '6+',\n",
    "    10: '6+',\n",
    "    11: '6+',\n",
    "    12: '6+',\n",
    "    13: '6+',\n",
    "    995: '0',\n",
    "}\n",
    "\n",
    "\n",
    "hh['HHsize_Group'] = hh['num_people'].map(hhsize_category_mapping)\n",
    "hh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabel the vehicle ownership categories as follows:\n",
    "\n",
    "    # HHTS Category ---- Summary Category\n",
    "    # 1   ----1\n",
    "    # 2  ---- 2\n",
    "    # 3  ---- 3\n",
    "    # 4  ---- 4\n",
    "    # 5  ---- 5+\n",
    "    # 6  ---- 5+\n",
    "    # 7  ---- 5+\n",
    "    # 8  ---- 5+\n",
    "\n",
    "veh_category_mapping = {\n",
    "    1 : '1',\n",
    "    2 : '2',\n",
    "    3 : '3',\n",
    "    4 : '4',\n",
    "    5 : '5+',\n",
    "    6 : '5+',\n",
    "    7 : '5+',\n",
    "    8 : '5+'\n",
    "}\n",
    "\n",
    "hh['Auto_Ownership_Group'] = hh['num_vehicles'].map(veh_category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing age\n",
    "persons['Age_Group_3'] = 0\n",
    "persons.loc[(persons.age >= 1) & (persons.age <=7), 'Age_Group_3'] = 1\n",
    "persons['Age_Group_1'] = 0\n",
    "persons.loc[(persons.age >= 8) & (persons.age <=9), 'Age_Group_1'] = 1 # added the max limit of 150, obviously age of more than 150 is not reasonable at least now!!\n",
    "persons['Age_Group_2'] = 0\n",
    "persons.loc[(persons.age >=10) & (persons.age <=11), 'Age_Group_2'] = 1\n",
    "\n",
    "# group persons data to hh level and create binary age group variables\n",
    "persons_hh = persons.groupby(['hh_id'], as_index=False). agg({\n",
    "    'Age_Group_1' : 'max',\n",
    "    'Age_Group_2' : 'max',\n",
    "    'Age_Group_3' : 'max'\n",
    "})\n",
    "\n",
    "hh = pd.merge(hh, persons_hh, how='left', on='hh_id')\n",
    "\n",
    "# Rename columns\n",
    "hh.rename(columns={'num_people': 'hhsize', 'income_detailed': 'income', 'num_vehicles' : 'auto_ownership'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CVM Cummary Results: Income\n",
    "hh_group = hh.groupby(['Income_Group']).sum()[['Food','Package','Service']]\n",
    "hh_attract = hh.groupby(['Income_Group']).sum()[['day_weight']]\n",
    "svy_hh_Income = np.divide(hh_group,hh_attract).reset_index()\n",
    "svy_hh_Income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishment Attractor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input data -- establishment file\n",
    "df_estab = pd.read_excel(os.path.join(calibration_raw_data_dir,\n",
    "                                      r\"SANDAG 2022 CV DataBase & Dictionaires_03_03_2023.xlsx\"),\n",
    "                                     sheet_name=r\"Establishment Data\")\n",
    "\n",
    "df_estab.set_index('company_id')\n",
    "#df_estab.head()\n",
    "\n",
    "df_estab.loc[:, 'emp_total'] = df_estab['employees_fulltime_count'] + df_estab['employees_parttime_count']\n",
    "\n",
    "df_expand = pd.read_excel(os.path.join(calibration_raw_data_dir,\n",
    "                                      r\"CVS_EstabExpansion.xlsx\"),\n",
    "                                     sheet_name=r\"CVS_Expansion_Totals\")\n",
    "df_expand.info()\n",
    "df_expand.SectorID.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for establishment expansion targets\n",
    "expandEstab = dict()\n",
    "expandEstab['Emp_0_9'] = dict(zip(df_expand['SectorID'],df_expand['Emp_0_9']))\n",
    "expandEstab['Emp_10p'] = dict(zip(df_expand['SectorID'],df_expand['Emp_10p']))\n",
    "\n",
    "# Add establishment population-level estimates (targets)\n",
    "df_estab.loc[df_estab['emp_total']<=9, 'emp_lt10'] = 1\n",
    "df_estab.loc[df_estab['emp_total']>9, 'emp_lt10'] = 0\n",
    "df_estab['emp_lt10'] = df_estab['emp_lt10'].astype(int)\n",
    "\n",
    "df_estab.loc[df_estab['emp_total']<=9, \\\n",
    "             'region_estab_wght'] = df_estab['base_location_Industry Group'].map(expandEstab['Emp_0_9'])\n",
    "\n",
    "df_estab.loc[df_estab['emp_total']>9, \\\n",
    "             'region_estab_wght'] = df_estab['base_location_Industry Group'].map(expandEstab['Emp_10p'])\n",
    "\n",
    "df_estab['region_estab_wght'] = df_estab['region_estab_wght'].astype('int64')\n",
    "#df_estab[['emp_total','base_location_Industry Group','emp_lt10','region_estab_wght']].head()\n",
    "\n",
    "# Calculate Establishment Weights\n",
    "estab_weights = df_estab.groupby(['region_estab_wght']).size().reset_index(name='num_estabs')\n",
    "estab_weights['estab_exp_weight'] = estab_weights['region_estab_wght'] / estab_weights['num_estabs']\n",
    "estab_weights = dict(zip(estab_weights['region_estab_wght'],estab_weights['estab_exp_weight']))\n",
    "\n",
    "df_estab.loc[:,'estab_exp_weight'] = df_estab['region_estab_wght'].map(estab_weights)\n",
    "df_estab[['emp_total','base_location_Industry Group','emp_lt10','region_estab_wght','estab_exp_weight']].head(10)\n",
    "df_estab = df_estab.drop(['region_estab_wght'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create industry group abbreviations\n",
    "\n",
    "ind_fullname = {\n",
    "1: \"Agriculture/Mining\",\n",
    "2: \"Manufacturing\",\n",
    "3: \"Industrial/Utilities\",\n",
    "4: \"Retail\",\n",
    "5: \"Wholesale\",\n",
    "6: \"Construction\",\n",
    "7: \"Transportation\",\n",
    "8: \"Info/Finance/Insurance/Real Estate/Professional services\",\n",
    "9: \"Education/Other public services\",\n",
    "10: \"Medical/Health Services\",\n",
    "11: \"Leisure/Accommodations and Food\",\n",
    "96: \"Other/Non-Classified\"\n",
    "}\n",
    "\n",
    "ind_abrv = {\n",
    "    1: \"AGM\",\n",
    "    2: \"MFG\",\n",
    "    3: \"IUT\",\n",
    "    4: \"RET\",\n",
    "    5: \"WHL\",\n",
    "    6: \"CON\",\n",
    "    7: \"TRN\",\n",
    "    8: \"IFR\",\n",
    "    9: \"EPO\",\n",
    "    10: \"MHS\",\n",
    "    11: \"LAF\",\n",
    "    96: \"OTH\"\n",
    "}\n",
    "\n",
    "# Reverse lookup\n",
    "abrv_indus = dict(zip(list(ind_abrv.values()), list(ind_abrv.keys())))\n",
    "\n",
    "df_estab['industry_abv'] = df_estab['base_location_Industry Group'].map(ind_abrv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of employees and devlieries to see outliers\n",
    "scatter = df_estab.plot.scatter(x='no_of_emp_work', y='no_of_deliveries', c='DarkBlue', title=\"Deliveries (y) vs Employees (x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers - all those with >=500 employees and/or >=50 deliveries (14 total records)\n",
    "print(\"Old Shape: \",df_estab.shape)\n",
    "\n",
    "bound_emp = 500\n",
    "bound_del = 50\n",
    "\n",
    "df_estab['outlier'] = np.where( (df_estab['no_of_emp_work']>=bound_emp) | (df_estab['no_of_deliveries']>=bound_del) ,1,0)\n",
    "df_estab_clean = df_estab #df_estab.drop(df_estab[df_estab.outlier==1].index)\n",
    "\n",
    "print(\"New Shape: \",df_estab_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Industry Groups (based on the patterns in the above crossclass)\n",
    "ind_aggregate = {\n",
    "    \"AGM\":3,\n",
    "    \"CON\":3,\n",
    "    \"EPO\":3,\n",
    "    \"IFR\":4,\n",
    "    \"IUT\":2,\n",
    "    \"LAF\":2,\n",
    "    \"MFG\":1,\n",
    "    \"MHS\":3,\n",
    "    \"RET\":1,\n",
    "    \"TRN\":3,\n",
    "    \"WHL\":1\n",
    "}\n",
    "df_estab_clean['ind_aggregate'] = df_estab_clean['industry_abv'].map(ind_aggregate)\n",
    "\n",
    "# Reverse lookup\n",
    "aggr_industries = {1:[], 2:[], 3:[], 4:[]}\n",
    "for key, value in ind_aggregate.items():\n",
    "        aggr_industries[value] += [key]\n",
    "print(aggr_industries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new variable to indicate non-zero delivery establishments\n",
    "df_estab_clean['nonzero_del'] = np.where( (df_estab_clean['no_of_deliveries']>0), 1, 0 )\n",
    "df_estab_clean['nonzero_del'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estab_clean['nonzero_del_wtd'] = df_estab_clean['nonzero_del'] * df_estab_clean['estab_exp_weight']\n",
    "nonZeroDelWtd = df_estab_clean.groupby('ind_aggregate')['nonzero_del_wtd'].sum()\n",
    "estabWtd = df_estab_clean.groupby('ind_aggregate')['estab_exp_weight'].sum()\n",
    "pctNonZeroDelWtd = np.round(nonZeroDelWtd / estabWtd, 4)\n",
    "pctNonZeroDelWtd = pd.DataFrame(pctNonZeroDelWtd, columns=[\"pct_nonzero_del\"]).reset_index()\n",
    "pctNonZeroDelWtd['aggr_industries'] = pctNonZeroDelWtd['ind_aggregate'].map(aggr_industries)\n",
    "\n",
    "svy_est_att_ind_grp = pctNonZeroDelWtd[['ind_aggregate','aggr_industries','pct_nonzero_del']].copy()\n",
    "print(svy_est_att_ind_grp.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estab_deliv = df_estab_clean[df_estab_clean['nonzero_del']==1].copy()\n",
    "df_estab_deliv['no_of_deliveries_wtd'] = df_estab_deliv['no_of_deliveries'] * df_estab_deliv['estab_exp_weight']\n",
    "numDelivWtd = df_estab_deliv.groupby('base_location_Industry Group')['no_of_deliveries_wtd'].sum()\n",
    "estabWtd = df_estab_deliv.groupby('base_location_Industry Group')['estab_exp_weight'].sum()\n",
    "meanDelivWtd = np.round(numDelivWtd / estabWtd, 4)\n",
    "meanDelivWtd = pd.DataFrame(meanDelivWtd, columns=[\"avg_num_deliveries\"]).reset_index()\n",
    "meanDelivWtd['Industry_Group_Name'] = meanDelivWtd['base_location_Industry Group'].map(ind_abrv)\n",
    "\n",
    "svy_est_att_ind_num = meanDelivWtd[['base_location_Industry Group','Industry_Group_Name','avg_num_deliveries']].copy()\n",
    "print(svy_est_att_ind_num.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input data -- establishment file\n",
    "df_estab = pd.read_excel(os.path.join(calibration_raw_data_dir,\n",
    "                                      r\"SANDAG 2022 CV DataBase & Dictionaires_03_03_2023.xlsx\"),\n",
    "                                     sheet_name=r\"Establishment Data\")\n",
    "\n",
    "df_estab.set_index('company_id')\n",
    "df_estab.loc[:, 'emp_total'] = df_estab['employees_fulltime_count'] + df_estab['employees_parttime_count']\n",
    "\n",
    "df_expand = pd.read_excel(os.path.join(calibration_raw_data_dir,\n",
    "                                      r\"CVS_EstabExpansion.xlsx\"),\n",
    "                                     sheet_name=r\"CVS_Expansion_Totals\")\n",
    "df_expand.SectorID.fillna(0, inplace=True)\n",
    "\n",
    "# Create dictionary for establishment expansion targets\n",
    "expandEstab = dict()\n",
    "expandEstab['Emp_0_9'] = dict(zip(df_expand['SectorID'],df_expand['Emp_0_9']))\n",
    "expandEstab['Emp_10p'] = dict(zip(df_expand['SectorID'],df_expand['Emp_10p']))\n",
    "\n",
    "# Add establishment population-level estimates (targets)\n",
    "df_estab.loc[df_estab['emp_total']<=9, 'emp_lt10'] = 1\n",
    "df_estab.loc[df_estab['emp_total']>9, 'emp_lt10'] = 0\n",
    "df_estab['emp_lt10'] = df_estab['emp_lt10'].astype(int)\n",
    "\n",
    "df_estab.loc[df_estab['emp_total']<=9, \\\n",
    "             'region_estab_wght'] = df_estab['base_location_Industry Group'].map(expandEstab['Emp_0_9'])\n",
    "\n",
    "df_estab.loc[df_estab['emp_total']>9, \\\n",
    "             'region_estab_wght'] = df_estab['base_location_Industry Group'].map(expandEstab['Emp_10p'])\n",
    "\n",
    "df_estab['region_estab_wght'] = df_estab['region_estab_wght'].astype('int64')\n",
    "#df_estab[['emp_total','base_location_Industry Group','emp_lt10','region_estab_wght']].head()\n",
    "\n",
    "# Calculate Establishment Weights\n",
    "estab_weights = df_estab.groupby(['region_estab_wght']).size().reset_index(name='num_estabs')\n",
    "estab_weights['estab_exp_weight'] = estab_weights['region_estab_wght'] / estab_weights['num_estabs']\n",
    "estab_weights = dict(zip(estab_weights['region_estab_wght'],estab_weights['estab_exp_weight']))\n",
    "\n",
    "df_estab.loc[:,'estab_exp_weight'] = df_estab['region_estab_wght'].map(estab_weights)\n",
    "df_estab[['emp_total','base_location_Industry Group','emp_lt10','region_estab_wght','estab_exp_weight']].head(10)\n",
    "df_estab = df_estab.drop(['region_estab_wght'], axis=1)\n",
    "\n",
    "# Finalize Establishment Weights in Table\n",
    "estab_wts = round(df_estab.groupby(['base_location_Industry Group','emp_lt10'])['estab_exp_weight'].mean().reset_index(),3)\n",
    "\n",
    "# Create industry group abbreviations\n",
    "\n",
    "ind_fullname = {\n",
    "1: \"Agriculture/Mining\",\n",
    "2: \"Manufacturing\",\n",
    "3: \"Industrial/Utilities\",\n",
    "4: \"Retail\",\n",
    "5: \"Wholesale\",\n",
    "6: \"Construction\",\n",
    "7: \"Transportation\",\n",
    "8: \"Info/Finance/Insurance/Real Estate/Professional services\",\n",
    "9: \"Education/Other public services\",\n",
    "10: \"Medical/Health Services\",\n",
    "11: \"Leisure/Accommodations and Food\",\n",
    "96: \"Other/Non-Classified\"\n",
    "}\n",
    "\n",
    "ind_abrv = {\n",
    "    1: \"AGM\",\n",
    "    2: \"MFG\",\n",
    "    3: \"IUT\",\n",
    "    4: \"RET\",\n",
    "    5: \"WHL\",\n",
    "    6: \"CON\",\n",
    "    7: \"TRN\",\n",
    "    8: \"IFR\",\n",
    "    9: \"EPO\",\n",
    "    10: \"MHS\",\n",
    "    11: \"LAF\",\n",
    "    96: \"OTH\"\n",
    "}\n",
    "\n",
    "# Reverse lookup\n",
    "abrv_indus = dict(zip(list(ind_abrv.values()), list(ind_abrv.keys())))\n",
    "\n",
    "df_estab['industry_abv'] = df_estab['base_location_Industry Group'].map(ind_abrv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Industry Groups (based on the patterns in the above crossclass)\n",
    "ind_aggregate = {\n",
    "    \"AGM\": 1,\n",
    "    \"MFG\": 1,\n",
    "    \"IUT\": 2,\n",
    "    \"RET\": 2,\n",
    "    \"WHL\": 1,\n",
    "    \"CON\": 2,\n",
    "    \"TRN\": 2,\n",
    "    \"IFR\": 3,\n",
    "    \"EPO\": 4,\n",
    "    \"MHS\": 4,\n",
    "    \"LAF\": 3\n",
    "    #\"MIL\": 5\n",
    "}\n",
    "\n",
    "df_estab['ind_aggregate'] = df_estab['industry_abv'].map(ind_aggregate)\n",
    "\n",
    "# Reverse lookup\n",
    "aggr_industries = {1:[], 2:[], 3:[], 4:[]}\n",
    "for key, value in ind_aggregate.items():\n",
    "    aggr_industries[value] += [key]\n",
    "\n",
    "# Create dependent variable\n",
    "# we are saying establishment has at least one route if EITHER of the following are true:\n",
    "# no_of_from_deliveries > 0\n",
    "# Participated in travel survey\n",
    "df_estab['routes>0'] = np.where( (df_estab['no_of_from_deliveries']>0) | (df_estab['Participated in Travel Survey?']==\"YES\"),1,0)\n",
    "\n",
    "df_estab_clean = df_estab.drop(df_estab[df_estab.no_of_emp_work>1000].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estab_clean['nonzero_rts_wtd'] = df_estab_clean['routes>0'] * df_estab_clean['estab_exp_weight']\n",
    "nonZeroRtsWtd = df_estab_clean.groupby('ind_aggregate')['nonzero_rts_wtd'].sum()\n",
    "estabWtd = df_estab_clean.groupby('ind_aggregate')['estab_exp_weight'].sum()\n",
    "pctnonZeroRtsWtd = np.round(nonZeroRtsWtd / estabWtd, 4)\n",
    "pctnonZeroRtsWtd = pd.DataFrame(pctnonZeroRtsWtd, columns=[\"pct_nonzero_rts\"]).reset_index()\n",
    "pctnonZeroRtsWtd['aggr_industries'] = pctnonZeroRtsWtd['ind_aggregate'].map(aggr_industries)\n",
    "pctnonZeroRtsWtd = pctnonZeroRtsWtd[['ind_aggregate', 'aggr_industries', 'pct_nonzero_rts']]\n",
    "svy_tot_rte_indgrp = pctnonZeroRtsWtd.copy()\n",
    "svy_tot_rte_indgrp['pct_nonzero_rts'] = svy_tot_rte_indgrp['pct_nonzero_rts'] * 1.2\n",
    "print(svy_tot_rte_indgrp.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survey Data\n",
    "industries = {\n",
    "    \"Agriculture/Mining\" : 1,\n",
    "    \"Construction\" : 6,\n",
    "    \"Education/Other public services\" : 9,\n",
    "    \"Industrial/Utilities\": 3,\n",
    "    \"Info/Finance/Insurance/Real Estate/Professional services\": 8,\n",
    "    \"Leisure/Accommodations and Food\": 11,\n",
    "    \"Manufacturing\" : 2,\n",
    "    \"Medical/Health Services\" : 10,\n",
    "    \"Retail\" : 4,\n",
    "    \"Transportation\" : 7,\n",
    "    \"Wholesale\" : 5,\n",
    "    \"Military\" : 12,\n",
    "}\n",
    "\n",
    "svy_cvm_routes = pd.read_excel(_join(calibration_data_dir, \"CV_Routes_20240129.xlsx\"))\n",
    "svy_cvm_routes['industry_group'] = svy_cvm_routes['industry_group'].str.strip()\n",
    "svy_cvm_routes['industry_num'] = svy_cvm_routes['industry_group'].map(industries)\n",
    "\n",
    "\n",
    "svy_tot_rte_indnum = svy_cvm_routes.groupby(['industry_num'])['expnsn_factor'].sum().reset_index().rename(\n",
    "    columns={'expnsn_factor': 'total_routes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svy_cvm_routes['group'] = 0\n",
    "\n",
    "# Assign the group based on the route purpose, customer type and vehicle type\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Goods') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Mixed Residential and Non-residential') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'LCV'), 'group'] = 'Goods_Mixed_LCV'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Goods') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Mixed Residential and Non-residential') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'MUT'), 'group'] = 'Goods_Mixed_MUT'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Goods') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Mixed Residential and Non-residential') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'SUT'), 'group'] = 'Goods_Mixed_SUT'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Goods') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Non-Residential Only') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'LCV'), 'group'] = 'Goods_NonRes_LCV'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Goods') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Non-Residential Only') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'MUT'), 'group'] = 'Goods_NonRes_MUT'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Goods') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Non-Residential Only') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'SUT'), 'group'] = 'Goods_NonRes_SUT'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Goods') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Residential Only') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'LCV'), 'group'] = 'Goods_Res_LCV'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Goods') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Residential Only') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'MUT'), 'group'] = 'Goods_Res_MUT'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Goods') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Residential Only') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'SUT'), 'group'] = 'Goods_Res_SUT'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Maintenance/Other') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'LCV'), 'group'] = 'Maintenance_LCV'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Maintenance/Other') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'MUT'), 'group'] = 'Maintenance_MUT'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Maintenance/Other') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'SUT'), 'group'] = 'Maintenance_SUT'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Service') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Mixed Residential and Non-residential') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'LCV'), 'group'] = 'Service_Mixed_LCV'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Service') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Mixed Residential and Non-residential') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'MUT'), 'group'] = 'Service_Mixed_MUT'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Service') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Mixed Residential and Non-residential') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'SUT'), 'group'] = 'Service_Mixed_SUT'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Service') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Non-Residential Only') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'LCV'), 'group'] = 'Service_NonRes_LCV'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Service') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Non-Residential Only') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'MUT'), 'group'] = 'Service_NonRes_MUT'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Service') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Non-Residential Only') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'SUT'), 'group'] = 'Service_NonRes_SUT'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Service') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Residential Only') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'LCV'), 'group'] = 'Service_Res_LCV'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Service') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Residential Only') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'MUT'), 'group'] = 'Service_Res_MUT'\n",
    "\n",
    "svy_cvm_routes.loc[(svy_cvm_routes['primary_purp'] == 'Service') &\n",
    "                 (svy_cvm_routes['customer_type'] == 'Residential Only') &\n",
    "                 (svy_cvm_routes['veh_type'] == 'SUT'), 'group'] = 'Service_Res_SUT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpc_alt = {\n",
    "    \"Goods_Mixed_LCV\":1,\n",
    "    \"Goods_Mixed_MUT\":2,\n",
    "    \"Goods_Mixed_SUT\":3,\n",
    "    \"Goods_NonRes_LCV\":4,\n",
    "    \"Goods_NonRes_MUT\":5,\n",
    "    \"Goods_NonRes_SUT\":6,\n",
    "    \"Goods_Res_LCV\":7,\n",
    "    \"Goods_Res_MUT\":8,\n",
    "    \"Goods_Res_SUT\":9,\n",
    "    \"Maintenance_LCV\":10,\n",
    "    \"Maintenance_MUT\":11,\n",
    "    \"Maintenance_SUT\":12,\n",
    "    \"Service_Mixed_LCV\":13,\n",
    "    \"Service_Mixed_MUT\":14,\n",
    "    \"Service_Mixed_SUT\":15,\n",
    "    \"Service_NonRes_LCV\":16,\n",
    "    \"Service_NonRes_MUT\":17,\n",
    "    \"Service_NonRes_SUT\":18,\n",
    "    \"Service_Res_LCV\":19,\n",
    "    \"Service_Res_MUT\":20,\n",
    "    \"Service_Res_SUT\":21,\n",
    "}\n",
    "\n",
    "# Map the group to the vpc_alt\n",
    "svy_cvm_routes['vpc_alt'] = svy_cvm_routes['group'].map(vpc_alt)\n",
    "\n",
    "# route generation by industry group\n",
    "route_purp_veh_smry = svy_cvm_routes.groupby(['vpc_alt', 'group'])['expnsn_factor'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Route Generation - TNC\n",
    "svy_tnc_routes = pd.read_excel(_join(calibration_data_dir, \"TNC_Routes_20240129.xlsx\"))\n",
    "\n",
    "# Expansion weights dictionary\n",
    "tnc_expwght = {'TNC_NonRestRetl': 3.78289, 'TNC_Restaurant': 12.86792, 'TNC_Retail': 19.11675}\n",
    "svy_tnc_routes['expnsn_factor'] = svy_tnc_routes['expnsn_factor'].astype('float')\n",
    "svy_tnc_routes.loc[:, 'expnsn_factor'] = svy_tnc_routes['industry_group'].map(tnc_expwght)\n",
    "\n",
    "svy_cvm_tnc_rte_gen = svy_tnc_routes.groupby(['industry_group'])['expnsn_factor'].sum().reset_index()\n",
    "\n",
    "# Get TNC Route Start times\n",
    "svy_tnc_st = svy_tnc_routes[['route_id','start_tod', 'expnsn_factor']].copy()\n",
    "\n",
    "# Extract hour and minute from start_tod\n",
    "svy_tnc_st['Hour'] = svy_tnc_st['start_tod'].dt.hour\n",
    "svy_tnc_st['Minute'] = svy_tnc_st['start_tod'].dt.minute\n",
    "svy_tnc_st['Minute_Round'] = svy_tnc_st['Minute'].apply(lambda x: 0 if x < 30 else 0.5)\n",
    "svy_tnc_st['Hour_Minute'] = svy_tnc_st['Hour'] + svy_tnc_st['Minute_Round']\n",
    "svy_tnc_st['Hour_Minute'] = svy_tnc_st['Hour_Minute'].apply(lambda x: round(x, 2))\n",
    "\n",
    "# Assign TOD based on Hour_Minute\n",
    "tod_tnc_smry = svy_tnc_st.groupby(['Hour_Minute'])['expnsn_factor'].sum().reset_index()\n",
    "tod_tnc_smry['TOD'] = 'NA'\n",
    "tod_tnc_smry.loc[(tod_tnc_smry['Hour_Minute'] >= 3.0) & (tod_tnc_smry['Hour_Minute'] <6.0), 'TOD'] = 'EA'\n",
    "tod_tnc_smry.loc[(tod_tnc_smry['Hour_Minute'] >= 6.0) & (tod_tnc_smry['Hour_Minute'] <9.0), 'TOD'] = 'AM'\n",
    "tod_tnc_smry.loc[(tod_tnc_smry['Hour_Minute'] >= 9.0) & (tod_tnc_smry['Hour_Minute'] <15.5), 'TOD'] = 'MD'\n",
    "tod_tnc_smry.loc[(tod_tnc_smry['Hour_Minute'] >= 15.5) & (tod_tnc_smry['Hour_Minute'] <19.0), 'TOD'] = 'PM'\n",
    "tod_tnc_smry.loc[(tod_tnc_smry['Hour_Minute'] >= 19.0) & (tod_tnc_smry['Hour_Minute'] <24.0), 'TOD'] = 'EV'\n",
    "tod_tnc_smry.loc[(tod_tnc_smry['Hour_Minute'] >= 0.0) & (tod_tnc_smry['Hour_Minute'] <3.0), 'TOD'] = 'EV'\n",
    "\n",
    "# Group by TOD and calculate the sum of expnsn_factor for CVM routes\n",
    "svy_rte_tnc_start_time_period = tod_tnc_smry.groupby(['TOD'])['expnsn_factor'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route Start Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CVM Routes file\n",
    "svy_cvm_routes = pd.read_excel(_join(calibration_data_dir, \"CV_Routes_20240129.xlsx\"))\n",
    "svy_cvm_st = svy_cvm_routes[['route_id','start_tod', 'expnsn_factor']].copy()\n",
    "\n",
    "# Extract hour and minute from start_tod\n",
    "svy_cvm_st['Hour'] = svy_cvm_st['start_tod'].dt.hour\n",
    "svy_cvm_st['Minute'] = svy_cvm_st['start_tod'].dt.minute\n",
    "svy_cvm_st['Minute_Round'] = svy_cvm_st['Minute'].apply(lambda x: 0 if x < 30 else 0.5)\n",
    "svy_cvm_st['Hour_Minute'] = svy_cvm_st['Hour'] + svy_cvm_st['Minute_Round']\n",
    "svy_cvm_st['Hour_Minute'] = svy_cvm_st['Hour_Minute'].apply(lambda x: round(x, 2))\n",
    "\n",
    "# Assign TOD based on Hour_Minute\n",
    "tod_smry = svy_cvm_st.groupby(['Hour_Minute'])['expnsn_factor'].sum().reset_index()\n",
    "tod_smry['TOD'] = 'NA'\n",
    "tod_smry.loc[(tod_smry['Hour_Minute'] >= 3.0) & (tod_smry['Hour_Minute'] <6.0), 'TOD'] = 'EA'\n",
    "tod_smry.loc[(tod_smry['Hour_Minute'] >= 6.0) & (tod_smry['Hour_Minute'] <9.0), 'TOD'] = 'AM'\n",
    "tod_smry.loc[(tod_smry['Hour_Minute'] >= 9.0) & (tod_smry['Hour_Minute'] <15.5), 'TOD'] = 'MD'\n",
    "tod_smry.loc[(tod_smry['Hour_Minute'] >= 15.5) & (tod_smry['Hour_Minute'] <19.0), 'TOD'] = 'PM'\n",
    "tod_smry.loc[(tod_smry['Hour_Minute'] >= 19.0) & (tod_smry['Hour_Minute'] <24.0), 'TOD'] = 'EV'\n",
    "tod_smry.loc[(tod_smry['Hour_Minute'] >= 0.0) & (tod_smry['Hour_Minute'] <3.0), 'TOD'] = 'EV'\n",
    "\n",
    "# Group by TOD and calculate the sum of expnsn_factor for CVM routes\n",
    "svy_rte_start_time_period = tod_smry.groupby(['TOD'])['expnsn_factor'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route Origination Terminal Type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "svy_cvm_routes = pd.read_excel(_join(calibration_data_dir, \"CV_Routes_20240129.xlsx\"))\n",
    "svy_tnc_routes = pd.read_excel(_join(calibration_data_dir, \"TNC_Routes_20240129.xlsx\"))\n",
    "\n",
    "# get AM distances from skims for each mode for origin\n",
    "skims_dist = omx.open_file(_join(model_data_dir, \"traffic_skims_AM.omx\"))\n",
    "lcv_am_dist = array2df(np.array(skims_dist['TRK_L_DIST__AM']), cols=['orig', 'dest', 'am_dist'])\n",
    "sut_am_dist = array2df(np.array(skims_dist['TRK_M_DIST__AM']), cols=['orig', 'dest', 'am_dist'])\n",
    "mut_am_dist = array2df(np.array(skims_dist['TRK_H_DIST__AM']), cols=['orig', 'dest', 'am_dist'])\n",
    "skims_dist.close()\n",
    "\n",
    "# get MD distances from skims for each mode for terminal\n",
    "skims_dist = omx.open_file(_join(model_data_dir, \"traffic_skims_MD.omx\"))\n",
    "lcv_md_dist = array2df(np.array(skims_dist['TRK_L_DIST__MD']), cols=['orig', 'dest', 'md_dist'])\n",
    "sut_md_dist = array2df(np.array(skims_dist['TRK_M_DIST__MD']), cols=['orig', 'dest', 'md_dist'])\n",
    "mut_md_dist = array2df(np.array(skims_dist['TRK_H_DIST__MD']), cols=['orig', 'dest', 'md_dist'])\n",
    "skims_dist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge distances with routes for each mode - from establishment to origin\n",
    "print(len(svy_cvm_routes))\n",
    "svy_lcv_routes = svy_cvm_routes[svy_cvm_routes['veh_type'] == 'LCV']\n",
    "svy_lcv_routes = pd.merge(svy_lcv_routes, lcv_am_dist, left_on=['estab_taz', 'orig_taz'], right_on=['orig', 'dest'], how='left')\n",
    "\n",
    "svy_sut_routes = svy_cvm_routes[svy_cvm_routes['veh_type'] == 'SUT']\n",
    "svy_sut_routes = pd.merge(svy_sut_routes, sut_am_dist, left_on=['estab_taz', 'orig_taz'], right_on=['orig', 'dest'], how='left')\n",
    "\n",
    "svy_mut_routes = svy_cvm_routes[svy_cvm_routes['veh_type'] == 'MUT']\n",
    "svy_mut_routes = pd.merge(svy_mut_routes, mut_am_dist, left_on=['estab_taz', 'orig_taz'], right_on=['orig', 'dest'], how='left')\n",
    "\n",
    "svy_cvm_routes = pd.concat([svy_lcv_routes, svy_sut_routes, svy_mut_routes])\n",
    "svy_cvm_routes = svy_cvm_routes.reset_index(drop=True)\n",
    "\n",
    "svy_cvm_routes = svy_cvm_routes.rename(columns={'am_dist': 'dist_estab2orig'})\n",
    "print(len(svy_cvm_routes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge distances with routes for each mode - from establishment to destination\n",
    "print(len(svy_cvm_routes))\n",
    "svy_lcv_routes = svy_cvm_routes[svy_cvm_routes['veh_type'] == 'LCV']\n",
    "svy_lcv_routes = pd.merge(svy_lcv_routes, lcv_md_dist, left_on=['estab_taz', 'dest_taz'], right_on=['orig', 'dest'], how='left')\n",
    "\n",
    "svy_sut_routes = svy_cvm_routes[svy_cvm_routes['veh_type'] == 'SUT']\n",
    "svy_sut_routes = pd.merge(svy_sut_routes, sut_md_dist, left_on=['estab_taz', 'dest_taz'], right_on=['orig', 'dest'], how='left')\n",
    "\n",
    "svy_mut_routes = svy_cvm_routes[svy_cvm_routes['veh_type'] == 'MUT']\n",
    "svy_mut_routes = pd.merge(svy_mut_routes, mut_md_dist, left_on=['estab_taz', 'dest_taz'], right_on=['orig', 'dest'], how='left')\n",
    "\n",
    "svy_cvm_routes = pd.concat([svy_lcv_routes, svy_sut_routes, svy_mut_routes])\n",
    "svy_cvm_routes = svy_cvm_routes.reset_index(drop=True)\n",
    "\n",
    "svy_cvm_routes = svy_cvm_routes.rename(columns={'md_dist': 'dist_estab2dest'})\n",
    "print(len(svy_cvm_routes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svy_cv_routes_non_na_estab_orig = svy_cvm_routes[svy_cvm_routes['dist_estab2orig'].notna()] #some orig_taz couldn't be geolocated\n",
    "svy_cv_routes_non_na_orig_dest = svy_cvm_routes[svy_cvm_routes['dist_estab2dest'].notna()] #some dest_taz couldn't be geolocated\n",
    "print(len(svy_cv_routes_non_na_estab_orig))\n",
    "print(len(svy_cv_routes_non_na_orig_dest))\n",
    "#cv_routes_na[['estab_taz','orig_taz']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svy_indg_orig_type = svy_cv_routes_non_na_estab_orig.groupby(['orig_type', 'industry_group'])['expnsn_factor'].sum().reset_index()\n",
    "svy_veh_orig_type = svy_cv_routes_non_na_estab_orig.groupby(['orig_type', 'veh_type'])['expnsn_factor'].sum().reset_index()\n",
    "\n",
    "svy_cv_routes_non_na_estab_orig['dist_estab2orig_wtd'] = svy_cv_routes_non_na_estab_orig['expnsn_factor'] * svy_cv_routes_non_na_estab_orig['dist_estab2orig']\n",
    "svy_veh_orig_type_mean_dist1 = svy_cv_routes_non_na_estab_orig.groupby(['orig_type'])['dist_estab2orig_wtd'].sum().reset_index()\n",
    "svy_veh_orig_type_mean_dist2 = svy_cv_routes_non_na_estab_orig.groupby(['orig_type'])['expnsn_factor'].sum().reset_index()\n",
    "\n",
    "svy_veh_orig_type_mean_dist = pd.merge(svy_veh_orig_type_mean_dist1, svy_veh_orig_type_mean_dist2, on=['orig_type'])\n",
    "svy_veh_orig_type_mean_dist['mean_dist'] = svy_veh_orig_type_mean_dist['dist_estab2orig_wtd'] / svy_veh_orig_type_mean_dist['expnsn_factor']\n",
    "svy_veh_orig_type_mean_dist = svy_veh_orig_type_mean_dist[['orig_type', 'mean_dist']]\n",
    "\n",
    "svy_indg_dest_type = svy_cv_routes_non_na_orig_dest.groupby(['dest_type', 'industry_group'])['expnsn_factor'].sum().reset_index()\n",
    "svy_veh_dest_type = svy_cv_routes_non_na_orig_dest.groupby(['dest_type', 'veh_type'])['expnsn_factor'].sum().reset_index()\n",
    "\n",
    "svy_veh_dest_type_mean_dist1 = svy_cv_routes_non_na_estab_orig.groupby(['dest_type',])['dist_estab2orig_wtd'].sum().reset_index()\n",
    "svy_veh_dest_type_mean_dist2 = svy_cv_routes_non_na_estab_orig.groupby(['dest_type',])['expnsn_factor'].sum().reset_index()\n",
    "svy_veh_dest_type_mean_dist = pd.merge(svy_veh_dest_type_mean_dist1, svy_veh_dest_type_mean_dist2, on=['dest_type'])\n",
    "svy_veh_dest_type_mean_dist['mean_dist'] = svy_veh_dest_type_mean_dist['dist_estab2orig_wtd'] / svy_veh_dest_type_mean_dist['expnsn_factor']\n",
    "svy_veh_dest_type_mean_dist = svy_veh_dest_type_mean_dist[['dest_type', 'mean_dist']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Stop location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distances from skims for each mode\n",
    "time_period = ['AM', 'MD', 'PM', 'EV', 'EA']\n",
    "\n",
    "for tp in time_period:\n",
    "    skims_dist = omx.open_file(_join(model_data_dir, \"traffic_skims_\" + tp + \".omx\"))\n",
    "    globals()['lcv_' + tp.lower() + '_dist'] = array2df(np.array(skims_dist['TRK_L_DIST__' + tp]), cols=['orig', 'dest', '_dist'])\n",
    "    globals()['sut_' + tp.lower() + '_dist'] = array2df(np.array(skims_dist['TRK_M_DIST__' + tp]), cols=['orig', 'dest', '_dist'])\n",
    "    globals()['mut_' + tp.lower() + '_dist'] = array2df(np.array(skims_dist['TRK_H_DIST__' + tp]), cols=['orig', 'dest', '_dist'])\n",
    "    globals()['tnc_' + tp.lower() + '_dist'] = array2df(np.array(skims_dist['TRK_L_DIST__' + tp]), cols=['orig', 'dest', '_dist'])\n",
    "    skims_dist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input files\n",
    "svy_cvm_trips = pd.read_excel(_join(calibration_data_dir, \"CV_Trips_20240129.xlsx\"))\n",
    "svy_tnc_trips = pd.read_excel(_join(calibration_data_dir, \"TNC_Trips_20240129.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tod_crwk = pd.read_csv(_join(\"tod_crswlk.csv\"))\n",
    "tod_crwk = dict(zip(tod_crwk['start_time'], tod_crwk['time_period']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svy_purposes = ['Base', 'Goods_Delivery', 'Goods_Pickup', 'Home', 'Maintenance/Other', 'Originate', 'Service', 'Terminal Destination']\n",
    "svy_purp_smry_temp = pd.DataFrame(list(product(svy_purposes, repeat=2)), columns=['o_act_seg_name', 'd_act_seg_name'])\n",
    "\n",
    "tod = ['AM', 'MD', 'PM', 'EV', 'EA']\n",
    "\n",
    "vtype = ['LCV' , 'SUT', 'MUT']\n",
    "svy_vtype_smry_temp = pd.DataFrame(list(vtype), columns=['veh_type'])\n",
    "\n",
    "svy_dtype = ['OtherNonResidential', 'Residential', 'Base', 'Warehouse', 'TransportNode']\n",
    "svy_dtype_smry_temp = pd.DataFrame(list(svy_dtype), columns=['dest_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add distance based on time period to svy data\n",
    "print(f\"Before Merge {len(svy_cvm_trips)}\")\n",
    "\n",
    "svy_all_cvm_trips = []\n",
    "vehicles = ['lcv', 'sut', 'mut']\n",
    "for tp in time_period:\n",
    "    for vehicle in vehicles:\n",
    "        svy_temp = svy_cvm_trips.loc[(svy_cvm_trips['tod'] == tp) & (svy_cvm_trips['veh_type'] == vehicle.upper())]\n",
    "        svy_trips = svy_temp.merge(globals()[vehicle + '_' + tp.lower() + '_dist'], left_on=['o_taz', 'd_taz'], right_on=['orig', 'dest'], how='left')\n",
    "        svy_trips = svy_trips.drop(['orig', 'dest'], axis=1)\n",
    "        svy_all_cvm_trips.append(svy_trips)\n",
    "\n",
    "svy_cvm_trips_test = pd.concat(svy_all_cvm_trips)\n",
    "print(f\"After Merge {len(svy_cvm_trips_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svy_cvm_trips = svy_cvm_trips_test.copy()\n",
    "svy_cvm_trips.loc[svy_cvm_trips['trip_number'] == 1, 'o_act_seg_name'] = 'Originate'\n",
    "svy_cvm_trips.loc[svy_cvm_trips['last_trip'] == True, 'd_act_seg_name'] = 'Terminal Destination'\n",
    "svy_cvm_trips['route_start_hour'] = svy_cvm_trips['route_start_time'].dt.hour\n",
    "\n",
    "# filtering trips from Base to Base and Home to Home\n",
    "svy_cvm_trips = svy_cvm_trips[~((svy_cvm_trips['o_act_seg_name'] == 'Base') & (svy_cvm_trips['d_act_seg_name'] == 'Base'))]\n",
    "svy_cvm_trips = svy_cvm_trips[~((svy_cvm_trips['o_act_seg_name'] == 'Home') & (svy_cvm_trips['d_act_seg_name'] == 'Home'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total trips by origin and destination activity segment name\n",
    "svy_od_act_seg_name = svy_cvm_trips.groupby(['o_act_seg_name', 'd_act_seg_name'])['expnsn_factor'].sum().reset_index()\n",
    "svy_od_act_seg_name = svy_purp_smry_temp.merge(svy_od_act_seg_name, on=['o_act_seg_name', 'd_act_seg_name'], how='left')\n",
    "svy_od_act_seg_name = svy_od_act_seg_name.fillna(0)\n",
    "svy_od_act_seg_name = svy_od_act_seg_name.pivot(index='o_act_seg_name', columns='d_act_seg_name', values='expnsn_factor').reset_index()\n",
    "\n",
    "# total trips by time period\n",
    "svy_cvm_tod_smry = svy_cvm_trips.groupby(['tod'])['expnsn_factor'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean distance by vehicle type\n",
    "svy_cvm_trips['dist_xExpsn'] = svy_cvm_trips['_dist'] * svy_cvm_trips['expnsn_factor']\n",
    "svy_cvm_mean_dist_vtype1 = svy_cvm_trips.groupby(['veh_type'])['dist_xExpsn'].sum().reset_index()\n",
    "svy_cvm_mean_dist_vtype2 = svy_cvm_trips.groupby(['veh_type'])['expnsn_factor'].sum().reset_index()\n",
    "svy_cvm_mean_dist_vtype = svy_cvm_mean_dist_vtype1.merge(svy_cvm_mean_dist_vtype2, on='veh_type')\n",
    "svy_cvm_mean_dist_vtype['mean_dist'] = svy_cvm_mean_dist_vtype['dist_xExpsn'] / svy_cvm_mean_dist_vtype['expnsn_factor']\n",
    "svy_cvm_mean_dist_vtype = svy_cvm_mean_dist_vtype[['veh_type', 'mean_dist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total trips by destination type\n",
    "svy_cvm_dest_type = svy_cvm_trips.groupby(['dest_type'])['expnsn_factor'].sum().reset_index()\n",
    "svy_cvm_dest_type = svy_dtype_smry_temp.merge(svy_cvm_dest_type, on='dest_type', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svy_tnc_trips = pd.read_excel(_join(calibration_data_dir, \"TNC_Trips_20240129.xlsx\"))\n",
    "\n",
    "# Expansion weights dictionary\n",
    "tnc_expwght = {'TNC_NonRestRetl': 3.78289, 'TNC_Restaurant': 12.86792, 'TNC_Retail': 19.11675}\n",
    "svy_tnc_trips['expnsn_factor'] = svy_tnc_trips['expnsn_factor'].astype('float')\n",
    "svy_tnc_trips.loc[:, 'expnsn_factor'] = svy_tnc_trips['industry_group'].map(tnc_expwght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add distance bases on time period to svy data\n",
    "print(f\"Before Merge {len(svy_tnc_trips)}\")\n",
    "\n",
    "svy_all_tnc_trips = []\n",
    "vehicles = 'tnc'\n",
    "for tp in time_period:\n",
    "        svy_temp = svy_tnc_trips.loc[(svy_tnc_trips['tod'] == tp)]\n",
    "        svy_trips = svy_temp.merge(globals()[vehicles + '_' + tp.lower() + '_dist'], left_on=['o_taz', 'd_taz'], right_on=['orig', 'dest'], how='left')\n",
    "        svy_trips = svy_trips.drop(['orig', 'dest'], axis=1)\n",
    "        svy_all_tnc_trips.append(svy_trips)\n",
    "\n",
    "svy_tnc_trips_test = pd.concat(svy_all_tnc_trips)\n",
    "print(f\"After Merge {len(svy_tnc_trips_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svy_tnc_trips = svy_tnc_trips_test.copy()\n",
    "svy_tnc_trips.loc[svy_tnc_trips['trip_number'] == 1, 'o_act_seg_name'] = 'Originate'\n",
    "\n",
    "svy_tnc_trips.loc[svy_tnc_trips['last_trip'] == True, 'd_act_seg_name'] = 'Terminal Destination'\n",
    "svy_tnc_trips = svy_tnc_trips[~((svy_tnc_trips['o_act_seg_name'] == 'Base') & (svy_tnc_trips['d_act_seg_name'] == 'Base'))]\n",
    "svy_tnc_trips = svy_tnc_trips[~((svy_tnc_trips['o_act_seg_name'] == 'Home') & (svy_tnc_trips['d_act_seg_name'] == 'Home'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summaries for TNC trips\n",
    "svy_tnc_od_act_seg_name = svy_tnc_trips.groupby(['o_act_seg_name', 'd_act_seg_name'])['expnsn_factor'].sum().reset_index()\n",
    "svy_tnc_od_act_seg_name = svy_purp_smry_temp.merge(svy_tnc_od_act_seg_name, on=['o_act_seg_name', 'd_act_seg_name'], how='left')\n",
    "svy_tnc_od_act_seg_name = svy_tnc_od_act_seg_name.fillna(0)\n",
    "svy_tnc_od_act_seg_name = svy_tnc_od_act_seg_name.pivot(index='o_act_seg_name', columns='d_act_seg_name', values='expnsn_factor').reset_index()\n",
    "\n",
    "svy_tnc_tod_smry = svy_tnc_trips.groupby(['tod'])['expnsn_factor'].sum().reset_index()\n",
    "svy_tnc_trp_dest_type = svy_tnc_trips.groupby(['dest_type'])['expnsn_factor'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TNC - mean distance by vehicle type\n",
    "svy_tnc_trips['veh_type'] = 'LCV'\n",
    "svy_tnc_trips['dist_xEspsn'] = svy_tnc_trips['_dist'] * svy_tnc_trips['expnsn_factor']\n",
    "svy_tnc_mean_dist_vtype1 = svy_tnc_trips.groupby('veh_type')['dist_xEspsn'].sum().reset_index()\n",
    "svy_tnc_mean_dist_vtype2 = svy_tnc_trips.groupby('veh_type')['expnsn_factor'].sum().reset_index()\n",
    "svy_tnc_mean_dist_vtype = svy_tnc_mean_dist_vtype1.merge(svy_tnc_mean_dist_vtype2, on='veh_type')\n",
    "svy_tnc_mean_dist_vtype['mean_dist'] = svy_tnc_mean_dist_vtype['dist_xEspsn'] / svy_tnc_mean_dist_vtype['expnsn_factor']\n",
    "svy_tnc_mean_dist_vtype = svy_tnc_mean_dist_vtype.drop(['dist_xEspsn', 'expnsn_factor'], axis=1)\n",
    "svy_tnc_mean_dist_vtype = svy_vtype_smry_temp.merge(svy_tnc_mean_dist_vtype, on='veh_type' , how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TNC Trips TOD\n",
    "svy_cvm_trips_tnc_tod_smry = svy_tnc_trips.groupby(['tod'])['expnsn_factor'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Excel writer object\n",
    "writer = pd.ExcelWriter('Final_CVM_Survey_Summary.xlsx')\n",
    "\n",
    "# Household Attractor Model\n",
    "svy_hh_group.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=0, index=False)\n",
    "svy_hh_Income.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=5, index=False)\n",
    "#svy_hh_Age_1.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=10, index=False)\n",
    "#svy_hh_Age_2.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=15, index=False)\n",
    "#svy_hh_Age_3.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=20, index=False)\n",
    "\n",
    "# Establishment Attractor Model\n",
    "svy_est_att_ind_grp.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=25, index=False)\n",
    "svy_est_att_ind_num.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=30, index=False)\n",
    "\n",
    "svy_tot_rte_indgrp.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=35, index=False)\n",
    "svy_tot_rte_indnum.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=40, index=False)\n",
    "\n",
    "# Route purpose and vehicle summary\n",
    "route_purp_veh_smry.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=45, index=False)\n",
    "\n",
    "# Route Start Time\n",
    "# svy_rte_start_time.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=50, index=False)\n",
    "svy_rte_start_time_period.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=55, index=False)\n",
    "\n",
    "# TNC Route Generation\n",
    "svy_cvm_tnc_rte_gen.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=60, index=False)\n",
    "\n",
    "# Origination and Terminal type\n",
    "svy_indg_orig_type.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=65, index=False)\n",
    "svy_veh_orig_type.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=70, index=False)\n",
    "svy_veh_orig_type_mean_dist.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=75, index=False)\n",
    "svy_indg_dest_type.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=81, index=False)\n",
    "svy_veh_dest_type.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=86, index=False)\n",
    "svy_veh_dest_type_mean_dist.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=91, index=False)\n",
    "\n",
    "# Next Stop Location\n",
    "svy_od_act_seg_name.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=96, index=False)\n",
    "svy_cvm_tod_smry.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=107, index=False)\n",
    "svy_cvm_dest_type.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=111, index=False)\n",
    "svy_cvm_mean_dist_vtype.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=115, index=False)\n",
    "\n",
    "# Next Stop Location TNC\n",
    "svy_tnc_od_act_seg_name.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=120, index=False)\n",
    "svy_tnc_tod_smry.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=131, index=False)\n",
    "svy_tnc_trp_dest_type.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=135, index=False)\n",
    "svy_tnc_mean_dist_vtype.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=139, index=False)\n",
    "\n",
    "# TNC Routes TOD\n",
    "svy_rte_tnc_start_time_period.to_excel(writer, sheet_name='SurveyData', startrow=2 , startcol=144, index=False)\n",
    "\n",
    "\n",
    "# Close the Excel writer\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
